{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2dca454",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping J0055+0146_ap3p4_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest = 10.30 arcsec)\n",
      "Skipping J0055+0146_ap3p8_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest = 10.30 arcsec)\n",
      "Skipping J0055+0146_ap4p2_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest = 10.30 arcsec)\n",
      "Skipping J0055+0146_ap4p6_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest = 10.30 arcsec)\n",
      "Skipping J0055+0146_ap5p0_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest = 10.30 arcsec)\n",
      "Skipping J0909+0440_ap3p4_ZPD24p2610_ERR0p0230.cat: No match within 2.0 arcsec (closest = 7.61 arcsec)\n",
      "Skipping J0909+0440_ap3p8_ZPD24p2610_ERR0p0230.cat: No match within 2.0 arcsec (closest = 7.61 arcsec)\n",
      "Skipping J0909+0440_ap4p2_ZPD24p2610_ERR0p0230.cat: No match within 2.0 arcsec (closest = 7.61 arcsec)\n",
      "Skipping J0909+0440_ap4p6_ZPD24p2610_ERR0p0230.cat: No match within 2.0 arcsec (closest = 7.61 arcsec)\n",
      "Skipping J0909+0440_ap5p0_ZPD24p2610_ERR0p0230.cat: No match within 2.0 arcsec (closest = 7.61 arcsec)\n",
      "Skipping J1350-0027_ap3p4_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest = 9.55 arcsec)\n",
      "Skipping J1350-0027_ap3p8_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest = 9.55 arcsec)\n",
      "Skipping J1350-0027_ap4p2_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest = 9.55 arcsec)\n",
      "Skipping J1350-0027_ap4p6_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest = 9.55 arcsec)\n",
      "Skipping J1350-0027_ap5p0_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest = 9.55 arcsec)\n",
      "Skipping J2131-4359_ap3p4_ZPD24p2810_ERR0p0140.cat: No match within 2.0 arcsec (closest = 11.45 arcsec)\n",
      "Skipping J2131-4359_ap3p8_ZPD24p2810_ERR0p0140.cat: No match within 2.0 arcsec (closest = 11.45 arcsec)\n",
      "Skipping J2131-4359_ap4p2_ZPD24p2810_ERR0p0140.cat: No match within 2.0 arcsec (closest = 11.45 arcsec)\n",
      "Skipping J2131-4359_ap4p6_ZPD24p2810_ERR0p0140.cat: No match within 2.0 arcsec (closest = 11.45 arcsec)\n",
      "Skipping J2131-4359_ap5p0_ZPD24p2810_ERR0p0140.cat: No match within 2.0 arcsec (closest = 11.45 arcsec)\n",
      "Skipping J2227-3323_ap3p4_ZPD24p1460_ERR0p0150.cat: No match within 2.0 arcsec (closest = 7.32 arcsec)\n",
      "Skipping J2227-3323_ap3p8_ZPD24p1460_ERR0p0150.cat: No match within 2.0 arcsec (closest = 7.32 arcsec)\n",
      "Skipping J2227-3323_ap4p2_ZPD24p1460_ERR0p0150.cat: No match within 2.0 arcsec (closest = 7.32 arcsec)\n",
      "Skipping J2227-3323_ap4p6_ZPD24p1460_ERR0p0150.cat: No match within 2.0 arcsec (closest = 7.32 arcsec)\n",
      "Skipping J2227-3323_ap5p0_ZPD24p1460_ERR0p0150.cat: No match within 2.0 arcsec (closest = 7.32 arcsec)\n",
      "Finished! Results saved to /home/jk/Desktop/reduced1/onlyfits/photometry_matches.txt\n",
      "Total computation time: 113.85 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import time\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# === SETTINGS ===\n",
    "catalog_folder = \"/utils/fits_folder/catalogs\"\n",
    "background_rms_folder = \"/utils/fits_folder/backgrounds_rms\"\n",
    "ods_file_path = \"/utils/aa61_fan_qso_database.ods\"\n",
    "output_file = \"/utils/photometry_matches.txt\"\n",
    "\n",
    "def find_closest_in_ods(ods_file, target_ra, target_dec):\n",
    "    df = pd.read_excel(ods_file, engine=\"odf\", header=[0, 1])\n",
    "    ra_cols = [col for col in df.columns if col[0].lower() == \"ra\"]\n",
    "    dec_cols = [col for col in df.columns if col[0].lower() == \"dec\"]\n",
    "\n",
    "    if not ra_cols or not dec_cols:\n",
    "        raise ValueError(\"ODS file must contain 'ra' and 'dec' columns\")\n",
    "\n",
    "    ra_col, dec_col = ra_cols[0], dec_cols[0]\n",
    "    df[ra_col] = pd.to_numeric(df[ra_col], errors=\"coerce\")\n",
    "    df[dec_col] = pd.to_numeric(df[dec_col], errors=\"coerce\")\n",
    "\n",
    "    target = SkyCoord(ra=target_ra * u.deg, dec=target_dec * u.deg)\n",
    "    coords = SkyCoord(ra=df[ra_col].values * u.deg, dec=df[dec_col].values * u.deg)\n",
    "\n",
    "    idx = target.separation(coords).argmin()\n",
    "    return df.iloc[idx][ra_col], df.iloc[idx][dec_col]\n",
    "\n",
    "def find_closest_in_catalog(cat_path, target_ra, target_dec, max_sep_arcsec=2.0):\n",
    "    cat = Table.read(cat_path, format=\"ascii\")\n",
    "\n",
    "    if not {\"ALPHA_J2000\", \"DELTA_J2000\"}.issubset(cat.colnames):\n",
    "        raise ValueError(f\"{cat_path} missing ALPHA_J2000 or DELTA_J2000\")\n",
    "\n",
    "    target = SkyCoord(ra=target_ra * u.deg, dec=target_dec * u.deg)\n",
    "    cat_coords = SkyCoord(ra=cat[\"ALPHA_J2000\"], dec=cat[\"DELTA_J2000\"], unit=(u.deg, u.deg))\n",
    "\n",
    "    sep = target.separation(cat_coords)\n",
    "    min_sep = sep.min()\n",
    "\n",
    "    if min_sep > max_sep_arcsec * u.arcsec:\n",
    "        raise ValueError(f\"No match within {max_sep_arcsec} arcsec (closest = {min_sep.arcsec:.2f} arcsec)\")\n",
    "\n",
    "    idx = sep.argmin()\n",
    "    row = cat[idx]\n",
    "\n",
    "    return {\n",
    "        \"ALPHA_J2000\": float(row[\"ALPHA_J2000\"]),\n",
    "        \"DELTA_J2000\": float(row[\"DELTA_J2000\"]),\n",
    "        \"MAG_APER\": row.get(\"MAG_APER\", None),\n",
    "        \"MAGERR_APER\": row.get(\"MAGERR_APER\", None),\n",
    "        \"FLUX_APER\": row.get(\"FLUX_APER\", None),\n",
    "        \"FLUXERR_APER\": row.get(\"FLUXERR_APER\", None),\n",
    "        \"X_IMAGE\": row.get(\"X_IMAGE\", None),\n",
    "        \"Y_IMAGE\": row.get(\"Y_IMAGE\", None),\n",
    "        \"FILENAME\": os.path.basename(cat_path)\n",
    "    }\n",
    "\n",
    "def parse_filename_coords(filename):\n",
    "    match = re.search(r\"J(\\d{2})(\\d{2})([+-])(\\d{2})(\\d{2})\", filename)\n",
    "    if not match:\n",
    "        raise ValueError(f\"Filename {filename} does not match pattern JHHMM+DDMM\")\n",
    "\n",
    "    ra_h = int(match.group(1))\n",
    "    ra_m = int(match.group(2))\n",
    "    sign = 1 if match.group(3) == \"+\" else -1\n",
    "    dec_d = int(match.group(4))\n",
    "    dec_m = int(match.group(5))\n",
    "\n",
    "    ra_deg = (ra_h + ra_m / 60) * 15\n",
    "    dec_deg = sign * (dec_d + dec_m / 60)\n",
    "\n",
    "    return ra_deg, dec_deg\n",
    "\n",
    "def extract_zpd_from_filename(filename):\n",
    "    zpd_match = re.search(r\"_ZPD([0-9p\\-]+)\", filename)\n",
    "    zpd_err_match = re.search(r\"_ERR([0-9p\\-]+)\", filename)\n",
    "\n",
    "    def convert_str_to_float(s):\n",
    "        return float(s.replace('p', '.')) if s else None\n",
    "\n",
    "    zpd = convert_str_to_float(zpd_match.group(1) if zpd_match else None)\n",
    "    zpd_err = convert_str_to_float(zpd_err_match.group(1) if zpd_err_match else None)\n",
    "    return zpd, zpd_err\n",
    "\n",
    "\n",
    "#DEFAULT method can be center, subpixel or exact (chose exact to best emulate SExtractor)\n",
    "#The in-use method is set further below\n",
    "def compute_background_error_photutils(rms_path, x_center, y_center, diameter, method=\"center\"):    \n",
    "    try:\n",
    "        with fits.open(rms_path) as hdul:\n",
    "            data = hdul[0].data\n",
    "\n",
    "        radius = diameter / 2.0\n",
    "        positions = [(x_center, y_center)]\n",
    "        aperture = CircularAperture(positions, r=radius)\n",
    "\n",
    "        squared_data = data**2\n",
    "        phot_table = aperture_photometry(squared_data, aperture, method=method)\n",
    "        sum_of_squares = phot_table['aperture_sum'][0]\n",
    "        background_error = np.sqrt(sum_of_squares)\n",
    "        \n",
    "        return background_error\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to compute background error from {rms_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    all_data = []\n",
    "\n",
    "    for cat_filename in sorted(os.listdir(catalog_folder)):\n",
    "        if not cat_filename.endswith(\".cat\"):\n",
    "            continue\n",
    "\n",
    "        base_match = re.match(r\"(J\\d{4}[+-]\\d{4}(\\(dup\\))?)\", cat_filename)\n",
    "        if base_match:\n",
    "            base = base_match.group(1)\n",
    "        else:\n",
    "            print(f\"Skipping {cat_filename}: could not extract base name\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rough_ra, rough_dec = parse_filename_coords(base)\n",
    "            precise_ra, precise_dec = find_closest_in_ods(ods_file_path, rough_ra, rough_dec)\n",
    "            cat_path = os.path.join(catalog_folder, cat_filename)\n",
    "            phot = find_closest_in_catalog(cat_path, precise_ra, precise_dec)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {cat_filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        ap_match = re.search(r\"_ap([0-9p]+)\", cat_filename)\n",
    "        aperture_diam = float(ap_match.group(1).replace('p', '.')) if ap_match else 1.0\n",
    "\n",
    "        zpd, zpd_err = extract_zpd_from_filename(cat_filename)\n",
    "\n",
    "        rms_filename = f\"{base}_ap{ap_match.group(1)}_background_rms.fits\"\n",
    "        rms_path = os.path.join(background_rms_folder, rms_filename)\n",
    "        background_error = compute_background_error_photutils(\n",
    "            rms_path, phot[\"X_IMAGE\"], phot[\"Y_IMAGE\"], aperture_diam, method=\"center\"    \n",
    "        )\n",
    "\n",
    "        all_data.append({\n",
    "            \"Base\": base,\n",
    "            \"Filename\": cat_filename,\n",
    "            \"PreciseRA\": precise_ra,\n",
    "            \"PreciseDEC\": precise_dec,\n",
    "            \"ALPHA_J2000\": phot[\"ALPHA_J2000\"],\n",
    "            \"DELTA_J2000\": phot[\"DELTA_J2000\"],\n",
    "            \"MAG_APER\": phot[\"MAG_APER\"],\n",
    "            \"MAGERR_APER\": phot[\"MAGERR_APER\"],\n",
    "            \"FLUX_APER\": phot[\"FLUX_APER\"],\n",
    "            \"FLUXERR_APER\": phot[\"FLUXERR_APER\"],\n",
    "            \"X_IMAGE\": phot[\"X_IMAGE\"],\n",
    "            \"Y_IMAGE\": phot[\"Y_IMAGE\"],\n",
    "            \"Aperture\": aperture_diam,\n",
    "            \"ZPD\": zpd,\n",
    "            \"ZPD_ERR\": zpd_err,\n",
    "            \"Background_ERR\": background_error\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        header = (\n",
    "            \"Filename\\tPreciseRA\\tPreciseDEC\\tALPHA_J2000\\tDELTA_J2000\\t\"\n",
    "            \"MAG_APER\\tMAGERR_APER\\tFLUX_APER\\tFLUXERR_APER\\tX_IMAGE\\tY_IMAGE\\t\"\n",
    "            \"Aperture\\tZPD\\tZPD_ERR\\tBackground_ERR\\n\"\n",
    "        )\n",
    "        f.write(header)\n",
    "        for _, r in df.iterrows():\n",
    "            line = (\n",
    "                f\"{r['Filename']}\\t{r['PreciseRA']:.6f}\\t{r['PreciseDEC']:.6f}\\t\"\n",
    "                f\"{r['ALPHA_J2000']:.6f}\\t{r['DELTA_J2000']:.6f}\\t\"\n",
    "                f\"{r['MAG_APER']}\\t{r['MAGERR_APER']}\\t{r['FLUX_APER']}\\t{r['FLUXERR_APER']}\\t\"\n",
    "                f\"{r['X_IMAGE']}\\t{r['Y_IMAGE']}\\t{r['Aperture']}\\t\"\n",
    "                f\"{r['ZPD']}\\t{r['ZPD_ERR']}\\t{r['Background_ERR']}\\n\"\n",
    "            )\n",
    "            f.write(line)\n",
    "\n",
    "    print(f\"Finished! Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Total computation time: {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b2f4a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping J0033-0125_ap5p0_ZPD24p4830_ERR0p0170.cat: No match within 2.0 arcsec (closest=25.62)\n",
      "Skipping J0046-2837_ap5p0_ZPD24p5070_ERR0p0250.cat: No match within 2.0 arcsec (closest=12.20)\n",
      "Skipping J0055+0146_ap5p0_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest=10.31)\n",
      "Skipping J0213-0626_ap5p0_ZPD24p4640_ERR0p0210.cat: No match within 2.0 arcsec (closest=8.11)\n",
      "Skipping J0313-1806_ap5p0_ZPD24p4280_ERR0p0390.cat: No match within 2.0 arcsec (closest=12.14)\n",
      "Skipping J0335-1547_ap5p0_ZPD24p2380_ERR0p0180.cat: No match within 2.0 arcsec (closest=6.34)\n",
      "Skipping J0525-2406_ap5p0_ZPD24p5200_ERR0p0090.cat: No match within 2.0 arcsec (closest=6.21)\n",
      "Skipping J0909+0440_ap5p0_ZPD24p3890_ERR0p0210.cat: No match within 2.0 arcsec (closest=12.57)\n",
      "Skipping J0929-1121_ap5p0_ZPD24p1710_ERR0p0100.cat: No match within 2.0 arcsec (closest=10.69)\n",
      "Skipping J1228-0233_ap5p0_ZPD24p2170_ERR0p0140.cat: No match within 2.0 arcsec (closest=33.32)\n",
      "Skipping J1350-0027_ap5p0_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest=17.60)\n",
      "Skipping J1357-0843_ap5p0_ZPD24p4340_ERR0p0130.cat: No match within 2.0 arcsec (closest=40.35)\n",
      "Skipping J1724+1901_ap5p0_ZPD24p2590_ERR0p0090.cat: No match within 2.0 arcsec (closest=15.81)\n",
      "Skipping J1748+2246_ap5p0_ZPD24p2520_ERR0p0080.cat: No match within 2.0 arcsec (closest=6.28)\n",
      "Skipping J2131-4359_ap5p0_ZPD24p1460_ERR0p0130.cat: No match within 2.0 arcsec (closest=15.49)\n",
      "Skipping J2147+0107_ap5p0_ZPD24p5070_ERR0p0100.cat: No match within 2.0 arcsec (closest=5.56)\n",
      "Skipping J2223+0326_ap5p0_ZPD24p3330_ERR0p0120.cat: No match within 2.0 arcsec (closest=8.50)\n",
      "Skipping J2227-3323_ap5p0_ZPD23p9330_ERR0p0170.cat: No match within 2.0 arcsec (closest=46.39)\n",
      "Skipping J2232+2930_ap5p0_ZPD24p2470_ERR0p0090.cat: No match within 2.0 arcsec (closest=13.26)\n",
      "Skipping J2318-0246_ap5p0_ZPD24p5360_ERR0p0170.cat: No match within 2.0 arcsec (closest=10.44)\n",
      "Skipping J2329-0301_ap5p0_ZPD24p4090_ERR0p0180.cat: No match within 2.0 arcsec (closest=20.82)\n",
      "Finished! Results saved to /home/jk/Desktop/reduced1/onlyfits/photometry_matches.txt\n",
      "Total computation time: 19.53 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import math\n",
    "import time\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "catalog_folder = \"/utils/fits_folder/catalogs\"\n",
    "background_rms_folder = \"/utils/fits_folder/backgrounds_rms\"\n",
    "ods_file_path = \"/utils/aa61_fan_qso_database.ods\"\n",
    "output_file = \"/utils/photometry_matches.txt\"\n",
    "FIDUCIAL_ZPD_ERR = 0.1\n",
    "\n",
    "def find_closest_in_ods(ods_file, target_ra, target_dec):\n",
    "    df = pd.read_excel(ods_file, engine=\"odf\", header=[0, 1])\n",
    "    ra_cols = [col for col in df.columns if col[0].lower() == \"ra\"]\n",
    "    dec_cols = [col for col in df.columns if col[0].lower() == \"dec\"]\n",
    "    redshift_cols = [col for col in df.columns if col[0].lower() == \"redshift\"]\n",
    "\n",
    "    if not ra_cols or not dec_cols:\n",
    "        raise ValueError(\"ODS file must contain 'ra' and 'dec' columns\")\n",
    "\n",
    "    ra_col, dec_col = ra_cols[0], dec_cols[0]\n",
    "    redshift_col = redshift_cols[0] if redshift_cols else None\n",
    "\n",
    "    df[ra_col] = pd.to_numeric(df[ra_col], errors=\"coerce\")\n",
    "    df[dec_col] = pd.to_numeric(df[dec_col], errors=\"coerce\")\n",
    "\n",
    "    target = SkyCoord(ra=target_ra * u.deg, dec=target_dec * u.deg)\n",
    "    coords = SkyCoord(ra=df[ra_col].values * u.deg, dec=df[dec_col].values * u.deg)\n",
    "\n",
    "    idx = target.separation(coords).argmin()\n",
    "    row = df.iloc[idx]\n",
    "    redshift = row[redshift_col] if redshift_col else None\n",
    "    return row[ra_col], row[dec_col], redshift\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    all_data = []\n",
    "\n",
    "    for cat_filename in sorted(os.listdir(catalog_folder)):\n",
    "        if not cat_filename.endswith(\".cat\"):\n",
    "            continue\n",
    "\n",
    "        base_match = re.match(r\"(J\\d{4}[+-]\\d{4}(\\(dup\\))?)\", cat_filename)\n",
    "        if base_match:\n",
    "            base = base_match.group(1)\n",
    "        else:\n",
    "            print(f\"Skipping {cat_filename}: could not extract base name\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            rough_ra, rough_dec = parse_filename_coords(base)\n",
    "            precise_ra, precise_dec, redshift = find_closest_in_ods(ods_file_path, rough_ra, rough_dec)\n",
    "\n",
    "            skycoord = SkyCoord(ra=precise_ra * u.deg, dec=precise_dec * u.deg)\n",
    "            precise_ra_sex = skycoord.ra.to_string(unit=u.hourangle, sep=':', precision=2, pad=True)\n",
    "            precise_dec_sex = skycoord.dec.to_string(unit=u.deg, sep=':', precision=2, alwayssign=True, pad=True)\n",
    "\n",
    "            cat_path = os.path.join(catalog_folder, cat_filename)\n",
    "            phot = find_closest_in_catalog(cat_path, precise_ra, precise_dec, max_sep=MAX_SEP_ARCSEC)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {cat_filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        ap_match = re.search(r\"_ap([0-9p]+)\", cat_filename)\n",
    "        aperture_diam = float(ap_match.group(1).replace('p', '.')) if ap_match else 1.0\n",
    "\n",
    "        zpd, zpd_err = extract_zpd_from_filename(cat_filename)\n",
    "\n",
    "        rms_filename = f\"{base}_ap{ap_match.group(1)}_background_rms.fits\"\n",
    "        rms_path = os.path.join(background_rms_folder, rms_filename)\n",
    "        background_error = compute_background_error_photutils(\n",
    "            rms_path, phot[\"X_IMAGE\"], phot[\"Y_IMAGE\"], aperture_diam, method=\"center\"\n",
    "        )\n",
    "\n",
    "        # NEW: Extract DATEOBS1 from background FITS header\n",
    "        try:\n",
    "            with fits.open(rms_path) as hdul:\n",
    "                dateobs_full = hdul[0].header.get(\"DATEOBS1\", \"\")\n",
    "                observation_date = dateobs_full.split(\"T\")[0] if \"T\" in dateobs_full else dateobs_full\n",
    "        except Exception as e:\n",
    "            observation_date = \"\"\n",
    "\n",
    "        magerr_plus, magerr_minus = flux_to_magerr_asymmetric(\n",
    "            phot[\"FLUX_APER\"], phot[\"FLUXERR_APER\"]\n",
    "        )\n",
    "\n",
    "        bg_magerr_upper, bg_magerr_lower = background_flux_to_magerr_asymmetric(\n",
    "            phot[\"FLUX_APER\"], background_error\n",
    "        )\n",
    "\n",
    "        magerrtot_upper = safe_quad_sum(zpd_err, bg_magerr_upper, magerr_plus)\n",
    "        magerrtot_lower = safe_quad_sum(zpd_err, bg_magerr_lower, magerr_minus)\n",
    "\n",
    "        all_data.append({\n",
    "            \"Base\": base,\n",
    "            \"Filename\": cat_filename,\n",
    "            \"PreciseRA\": precise_ra,\n",
    "            \"PreciseDEC\": precise_dec,\n",
    "            \"PreciseRA_sex\": precise_ra_sex,\n",
    "            \"PreciseDEC_sex\": precise_dec_sex,\n",
    "            \"Redshift\": redshift,\n",
    "            \"ALPHA_J2000\": phot[\"ALPHA_J2000\"],\n",
    "            \"DELTA_J2000\": phot[\"DELTA_J2000\"],\n",
    "            \"MAG_APER\": phot[\"MAG_APER\"],\n",
    "            \"MAGERR_APER\": phot[\"MAGERR_APER\"],\n",
    "            \"FLUX_APER\": phot[\"FLUX_APER\"],\n",
    "            \"FLUXERR_APER\": phot[\"FLUXERR_APER\"],\n",
    "            \"X_IMAGE\": phot[\"X_IMAGE\"],\n",
    "            \"Y_IMAGE\": phot[\"Y_IMAGE\"],\n",
    "            \"Aperture\": aperture_diam,\n",
    "            \"ZPD\": zpd,\n",
    "            \"ZPD_ERR\": zpd_err,\n",
    "            \"Background_ERR\": background_error,\n",
    "            \"MAGERR_FROMFLUXAPER_PLUS\": magerr_plus,\n",
    "            \"MAGERR_FROMFLUXAPER_MINUS\": magerr_minus,\n",
    "            \"Background_ERR_upper\": bg_magerr_upper,\n",
    "            \"Background_ERR_lower\": bg_magerr_lower,\n",
    "            \"MAGERRTOT_upper\": magerrtot_upper,\n",
    "            \"MAGERRTOT_lower\": magerrtot_lower,\n",
    "            \"ObservationDate\": observation_date\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    with open(output_file, \"w\") as f:\n",
    "        header = (\n",
    "            \"Filename\\tPreciseRA\\tPreciseDEC\\tPreciseRA_sex\\tPreciseDEC_sex\\tRedshift\\t\"\n",
    "            \"ALPHA_J2000\\tDELTA_J2000\\tMAG_APER\\tMAGERR_APER\\tFLUX_APER\\tFLUXERR_APER\\t\"\n",
    "            \"X_IMAGE\\tY_IMAGE\\tAperture\\tZPD\\tZPD_ERR\\tBackground_ERR\\t\"\n",
    "            \"MAGERR_FROMFLUXAPER_PLUS\\tMAGERR_FROMFLUXAPER_MINUS\\t\"\n",
    "            \"Background_ERR_upper\\tBackground_ERR_lower\\tMAGERRTOT_upper\\tMAGERRTOT_lower\\t\"\n",
    "            \"ObservationDate\\n\"\n",
    "        )\n",
    "        f.write(header)\n",
    "        for _, r in df.iterrows():\n",
    "            line = (\n",
    "                f\"{r['Filename']}\\t{r['PreciseRA']:.6f}\\t{r['PreciseDEC']:.6f}\\t\"\n",
    "                f\"{r['PreciseRA_sex']}\\t{r['PreciseDEC_sex']}\\t{r['Redshift']}\\t\"\n",
    "                f\"{r['ALPHA_J2000']:.6f}\\t{r['DELTA_J2000']:.6f}\\t\"\n",
    "                f\"{r['MAG_APER']}\\t{r['MAGERR_APER']}\\t{r['FLUX_APER']}\\t{r['FLUXERR_APER']}\\t\"\n",
    "                f\"{r['X_IMAGE']}\\t{r['Y_IMAGE']}\\t{r['Aperture']}\\t\"\n",
    "                f\"{r['ZPD']}\\t{r['ZPD_ERR']}\\t{r['Background_ERR']}\\t\"\n",
    "                f\"{r['MAGERR_FROMFLUXAPER_PLUS']}\\t{r['MAGERR_FROMFLUXAPER_MINUS']}\\t\"\n",
    "                f\"{r['Background_ERR_upper']}\\t{r['Background_ERR_lower']}\\t\"\n",
    "                f\"{r['MAGERRTOT_upper']}\\t{r['MAGERRTOT_lower']}\\t\"\n",
    "                f\"{r['ObservationDate']}\\n\"\n",
    "            )\n",
    "            f.write(line)\n",
    "\n",
    "    print(f\"Finished! Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Total computation time: {end - start:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7ded928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping J0055+0146_ap5p0_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest=10.30)\n",
      "Skipping J0909+0440_ap5p0_ZPD24p3890_ERR0p0210.cat: No match within 2.0 arcsec (closest=7.68)\n",
      "Skipping J1350-0027_ap5p0_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest=9.55)\n",
      "Skipping J1357-0843_ap5p0_ZPD24p4340_ERR0p0130.cat: No match within 2.0 arcsec (closest=3.83)\n",
      "Skipping J2227-3323_ap5p0_ZPD23p9330_ERR0p0170.cat: No match within 2.0 arcsec (closest=7.29)\n",
      "✓ Finished – output saved to /home/jk/Desktop/reduced1/onlyfits/photometry_matches.txt\n",
      "Total runtime: 25.66 s\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf‑8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Collect photometry from THELI *.cat files, match to fiducial quasar\n",
    "coordinates from an .ods spreadsheet, apply background‑noise estimates\n",
    "and zero‑point data, and write a tab‑separated output table.\n",
    "\n",
    "• matching radius is configurable with MAX_SEP_ARCSEC\n",
    "• observation date (DATEOBS1) is read from the *_background_rms.fits header\n",
    "• asymmetric flux and background errors are propagated in quadrature\n",
    "\"\"\"\n",
    "\n",
    "import os, re, time, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0.  SETTINGS (edit folder paths here)\n",
    "# ----------------------------------------------------------------------\n",
    "catalog_folder        = \"/utils/fits_folder/catalogs\"\n",
    "background_rms_folder = \"/utils/fits/folder/backgrounds_rms\"\n",
    "ods_file_path         = \"/utils/aa61_fan_qso_database.ods\"\n",
    "output_file           = \"/utils/photometry_matches.txt\"\n",
    "\n",
    "MAX_SEP_ARCSEC = 2.0          # <-- configurable match radius\n",
    "FIDUCIAL_ZPD_ERR = 0.10       # fallback ZP‑error if none in filename\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1.  HELPER FUNCTIONS\n",
    "# ----------------------------------------------------------------------\n",
    "def parse_filename_coords(name: str):\n",
    "    \"\"\"Parse 'JHHMM±DDMM...' string ⇒ (RA_deg, Dec_deg) rough coords.\"\"\"\n",
    "    m = re.search(r\"J(\\d{2})(\\d{2})([+-])(\\d{2})(\\d{2})\", name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse J‑name coordinates from '{name}'\")\n",
    "    ra_h, ra_m   = int(m.group(1)), int(m.group(2))\n",
    "    sign         = 1 if m.group(3) == \"+\" else -1\n",
    "    dec_d, dec_m = int(m.group(4)), int(m.group(5))\n",
    "    ra_deg  = (ra_h + ra_m/60) * 15.0\n",
    "    dec_deg = sign * (dec_d + dec_m/60)\n",
    "    return ra_deg, dec_deg\n",
    "\n",
    "\n",
    "def find_closest_in_ods(ods_file, target_ra, target_dec):\n",
    "    \"\"\"Return (precise RA, Dec, redshift) of closest entry in the ODS file.\"\"\"\n",
    "    df = pd.read_excel(ods_file, engine=\"odf\", header=[0, 1])\n",
    "    ra_col  = [c for c in df.columns if c[0].lower() == \"ra\"][0]\n",
    "    dec_col = [c for c in df.columns if c[0].lower() == \"dec\"][0]\n",
    "    z_col   = [c for c in df.columns if c[0].lower() == \"redshift\"]\n",
    "    z_col   = z_col[0] if z_col else None\n",
    "\n",
    "    df[ra_col]  = pd.to_numeric(df[ra_col],  errors=\"coerce\")\n",
    "    df[dec_col] = pd.to_numeric(df[dec_col], errors=\"coerce\")\n",
    "\n",
    "    target  = SkyCoord(target_ra*u.deg, target_dec*u.deg)\n",
    "    coords  = SkyCoord(df[ra_col].values*u.deg, df[dec_col].values*u.deg)\n",
    "    idx     = target.separation(coords).argmin()\n",
    "    row     = df.iloc[idx]\n",
    "    z_val   = row[z_col] if z_col else np.nan\n",
    "    return float(row[ra_col]), float(row[dec_col]), z_val\n",
    "\n",
    "\n",
    "def find_closest_in_catalog(cat_path, target_ra, target_dec, max_sep=2.0):\n",
    "    \"\"\"Return dict with photometry of closest source (≤ max_sep arcsec).\"\"\"\n",
    "    cat = Table.read(cat_path, format=\"ascii\")\n",
    "    if not {\"ALPHA_J2000\", \"DELTA_J2000\"}.issubset(cat.colnames):\n",
    "        raise ValueError(f\"{cat_path}: missing RA/Dec columns\")\n",
    "\n",
    "    target    = SkyCoord(target_ra*u.deg, target_dec*u.deg)\n",
    "    cat_coord = SkyCoord(cat[\"ALPHA_J2000\"], cat[\"DELTA_J2000\"], unit=\"deg\")\n",
    "    sep       = target.separation(cat_coord)\n",
    "    if sep.min() > max_sep*u.arcsec:\n",
    "        raise ValueError(f\"No match within {max_sep} arcsec (closest={sep.min().arcsec:.2f})\")\n",
    "    row = cat[sep.argmin()]\n",
    "    # return only numeric types or None (float(row[col]) if present else None)\n",
    "    def get(col):\n",
    "        return float(row[col]) if col in row.colnames and row[col] is not None else np.nan\n",
    "    return dict(\n",
    "        ALPHA_J2000 = get(\"ALPHA_J2000\"),\n",
    "        DELTA_J2000 = get(\"DELTA_J2000\"),\n",
    "        MAG_APER    = get(\"MAG_APER\"),\n",
    "        MAGERR_APER = get(\"MAGERR_APER\"),\n",
    "        FLUX_APER   = get(\"FLUX_APER\"),\n",
    "        FLUXERR_APER= get(\"FLUXERR_APER\"),\n",
    "        X_IMAGE     = get(\"X_IMAGE\"),\n",
    "        Y_IMAGE     = get(\"Y_IMAGE\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_zpd_from_filename(fname):\n",
    "    \"\"\"Return (ZP, ZP_err).  If missing, err falls back to FIDUCIAL_ZPD_ERR.\"\"\"\n",
    "    z  = re.search(r\"_ZPD([0-9p\\-]+)\", fname)\n",
    "    ze = re.search(r\"_ERR([0-9p\\-]+)\", fname)\n",
    "    zpd     = float(z.group(1).replace('p','.'))  if z else np.nan\n",
    "    zpd_err = float(ze.group(1).replace('p','.')) if ze else FIDUCIAL_ZPD_ERR\n",
    "    return zpd, zpd_err\n",
    "\n",
    "\n",
    "def flux_to_magerr_asymmetric(flux, flux_err):\n",
    "    \"\"\"Return (+err, -err) in magnitudes from flux ± flux_err.\"\"\"\n",
    "    if flux <= 0 or flux_err <= 0 or flux_err >= flux:\n",
    "        return np.nan, np.nan\n",
    "    mag     = -2.5 * np.log10(flux)\n",
    "    mag_plus  = -2.5 * np.log10(flux - flux_err)\n",
    "    mag_minus = -2.5 * np.log10(flux + flux_err)\n",
    "    err_plus  = mag_plus - mag\n",
    "    err_minus = mag - mag_minus\n",
    "    return err_plus, err_minus\n",
    "\n",
    "\n",
    "def background_flux_to_magerr_asymmetric(flux, bg_err):\n",
    "    \"\"\"Return (+err, -err) in magnitudes due to background noise.\"\"\"\n",
    "    if flux <= 0 or bg_err is None or bg_err <= 0 or bg_err >= flux:\n",
    "        return np.nan, np.nan\n",
    "    mag     = -2.5 * np.log10(flux)\n",
    "    mag_plus  = -2.5 * np.log10(flux - bg_err)\n",
    "    mag_minus = -2.5 * np.log10(flux + bg_err)\n",
    "    err_plus  = mag_plus - mag\n",
    "    err_minus = mag - mag_minus\n",
    "    return err_plus, err_minus\n",
    "\n",
    "\n",
    "def safe_quad_sum(*errs):\n",
    "    \"\"\"Quadrature sum, ignoring NaNs.\"\"\"\n",
    "    errs_clean = [e for e in errs if np.isfinite(e)]\n",
    "    return np.sqrt(np.sum(np.square(errs_clean))) if errs_clean else np.nan\n",
    "\n",
    "\n",
    "def compute_background_error_photutils(rms_path, x, y, diameter, method=\"center\"):\n",
    "    \"\"\"Integrate RMS map inside circular aperture → background noise.\"\"\"\n",
    "    try:\n",
    "        with fits.open(rms_path) as hdul:\n",
    "            data = hdul[0].data\n",
    "        r   = diameter/2.0\n",
    "        ap  = CircularAperture([(x, y)], r=r)\n",
    "        s2  = aperture_photometry(data**2, ap, method=method)['aperture_sum'][0]\n",
    "        return np.sqrt(s2)\n",
    "    except Exception as e:\n",
    "        print(f\"Background error failed ({os.path.basename(rms_path)}): {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2.  MAIN LOOP\n",
    "# ----------------------------------------------------------------------\n",
    "records = []\n",
    "\n",
    "for cat_file in sorted(os.listdir(catalog_folder)):\n",
    "    if not cat_file.endswith(\".cat\"):\n",
    "        continue\n",
    "\n",
    "    base_match = re.match(r\"(J\\d{4}[+-]\\d{4}(?:\\(dup\\))?)\", cat_file)\n",
    "    if not base_match:\n",
    "        print(f\"Skipping {cat_file}: cannot extract J‑name\")\n",
    "        continue\n",
    "    base = base_match.group(1)\n",
    "\n",
    "    try:\n",
    "        rough_ra, rough_dec = parse_filename_coords(base)\n",
    "        ra_prec, dec_prec, z = find_closest_in_ods(ods_file_path, rough_ra, rough_dec)\n",
    "\n",
    "        cat_path = os.path.join(catalog_folder, cat_file)\n",
    "        phot = find_closest_in_catalog(cat_path, ra_prec, dec_prec, max_sep=MAX_SEP_ARCSEC)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {cat_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # aperture diameter from filename\n",
    "    ap_match = re.search(r\"_ap([0-9p]+)\", cat_file)\n",
    "    aper_diam = float(ap_match.group(1).replace('p','.')) if ap_match else 1.0\n",
    "\n",
    "    zpd, zpd_err = extract_zpd_from_filename(cat_file)\n",
    "\n",
    "    # background RMS\n",
    "    rms_file = f\"{base}_ap{ap_match.group(1)}_background_rms.fits\"\n",
    "    rms_path = os.path.join(background_rms_folder, rms_file)\n",
    "    bg_err   = compute_background_error_photutils(\n",
    "                    rms_path, phot[\"X_IMAGE\"], phot[\"Y_IMAGE\"], aper_diam, method=\"exact\") #<-- set to exact ot center \n",
    "\n",
    "    # DATEOBS1 -> observation date\n",
    "    try:\n",
    "        with fits.open(rms_path) as hd:\n",
    "            dateobs1 = hd[0].header.get(\"DATEOBS1\", \"\")\n",
    "        obs_date = dateobs1.split('T')[0] if \"T\" in dateobs1 else dateobs1\n",
    "    except Exception:\n",
    "        obs_date = \"\"\n",
    "\n",
    "    # magnitude‑error budget\n",
    "    m_err_plus, m_err_minus = flux_to_magerr_asymmetric(\n",
    "                                phot[\"FLUX_APER\"], phot[\"FLUXERR_APER\"])\n",
    "    bg_err_plus, bg_err_minus = background_flux_to_magerr_asymmetric(\n",
    "                                phot[\"FLUX_APER\"], bg_err)\n",
    "\n",
    "    magerrtot_plus  = safe_quad_sum(zpd_err, bg_err_plus,  m_err_plus)\n",
    "    magerrtot_minus = safe_quad_sum(zpd_err, bg_err_minus, m_err_minus)\n",
    "\n",
    "    # SkyCoord pretty strings\n",
    "    c_prec = SkyCoord(ra_prec*u.deg, dec_prec*u.deg)\n",
    "    ra_sex = c_prec.ra.to_string(unit=u.hourangle, sep=':', precision=2, pad=True)\n",
    "    dec_sex= c_prec.dec.to_string(unit=u.deg,       sep=':', precision=2, pad=True, alwayssign=True)\n",
    "\n",
    "    records.append(dict(\n",
    "        Filename          = cat_file,\n",
    "        PreciseRA         = ra_prec,\n",
    "        PreciseDEC        = dec_prec,\n",
    "        PreciseRA_sex     = ra_sex,\n",
    "        PreciseDEC_sex    = dec_sex,\n",
    "        Redshift          = z,\n",
    "        ALPHA_J2000       = phot[\"ALPHA_J2000\"],\n",
    "        DELTA_J2000       = phot[\"DELTA_J2000\"],\n",
    "        MAG_APER          = phot[\"MAG_APER\"],\n",
    "        MAGERR_APER       = phot[\"MAGERR_APER\"],\n",
    "        FLUX_APER         = phot[\"FLUX_APER\"],\n",
    "        FLUXERR_APER      = phot[\"FLUXERR_APER\"],\n",
    "        X_IMAGE           = phot[\"X_IMAGE\"],\n",
    "        Y_IMAGE           = phot[\"Y_IMAGE\"],\n",
    "        Aperture          = aper_diam,\n",
    "        ZPD               = zpd,\n",
    "        ZPD_ERR           = zpd_err,\n",
    "        Background_ERR    = bg_err,\n",
    "        MAGERR_FROMFLUXAPER_PLUS   = m_err_plus,\n",
    "        MAGERR_FROMFLUXAPER_MINUS  = m_err_minus,\n",
    "        Background_ERR_upper       = bg_err_plus,\n",
    "        Background_ERR_lower       = bg_err_minus,\n",
    "        MAGERRTOT_upper            = magerrtot_plus,\n",
    "        MAGERRTOT_lower            = magerrtot_minus,\n",
    "        ObservationDate            = obs_date\n",
    "    ))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3.  WRITE TSV\n",
    "# ----------------------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(\n",
    "    output_file, sep=\"\\t\", index=False,\n",
    "    columns=[\n",
    "        \"Filename\",\"PreciseRA\",\"PreciseDEC\",\"PreciseRA_sex\",\"PreciseDEC_sex\",\"Redshift\",\n",
    "        \"ALPHA_J2000\",\"DELTA_J2000\",\"MAG_APER\",\"MAGERR_APER\",\n",
    "        \"FLUX_APER\",\"FLUXERR_APER\",\"X_IMAGE\",\"Y_IMAGE\",\"Aperture\",\n",
    "        \"ZPD\",\"ZPD_ERR\",\"Background_ERR\",\n",
    "        \"MAGERR_FROMFLUXAPER_PLUS\",\"MAGERR_FROMFLUXAPER_MINUS\",\n",
    "        \"Background_ERR_upper\",\"Background_ERR_lower\",\n",
    "        \"MAGERRTOT_upper\",\"MAGERRTOT_lower\",\"ObservationDate\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"✓ Finished – output saved to {output_file}\")\n",
    "print(f\"Total runtime: {time.time()-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c8e0491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping J0055+0146_ap5p0_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest=10.30)\n",
      "Skipping J0055+0146_ap7p0_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest=10.30)\n",
      "Skipping J0909+0440_ap5p0_ZPD24p3890_ERR0p0210.cat: No match within 2.0 arcsec (closest=7.68)\n",
      "Skipping J0909+0440_ap7p0_ZPD24p3890_ERR0p0210.cat: No match within 2.0 arcsec (closest=7.68)\n",
      "Skipping J1350-0027_ap5p0_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest=9.55)\n",
      "Skipping J1350-0027_ap7p0_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest=9.55)\n",
      "Skipping J1357-0843_ap5p0_ZPD24p4340_ERR0p0130.cat: No match within 2.0 arcsec (closest=3.83)\n",
      "Skipping J1357-0843_ap7p0_ZPD24p4340_ERR0p0130.cat: No match within 2.0 arcsec (closest=3.83)\n",
      "Skipping J2227-3323_ap5p0_ZPD23p9330_ERR0p0170.cat: No match within 2.0 arcsec (closest=7.29)\n",
      "Skipping J2227-3323_ap7p0_ZPD23p9330_ERR0p0170.cat: No match within 2.0 arcsec (closest=7.29)\n",
      "✓ Finished – output saved to /home/jk/Desktop/reduced1/onlyfits/photometry_matches.txt\n",
      "Total runtime: 40.61 s\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf‑8 -*-\n",
    "\n",
    "import os, re, time, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0.  SETTINGS\n",
    "# ----------------------------------------------------------------------\n",
    "catalog_folder        = \"/utils/fits_folder/catalogs\"\n",
    "background_rms_folder = \"/utils/fits_folder/backgrounds_rms\"\n",
    "ods_file_path         = \"/utils/aa61_fan_qso_database.ods\"\n",
    "output_file           = \"/utils/photometry_matches.tsv\"\n",
    "\n",
    "MAX_SEP_ARCSEC = 2.0          # match radius of precise RA/DEC from Fan23 with catalog detections\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1.  HELPER FUNCTIONS\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# reading rough coordinates from .cat filenames\n",
    "def parse_filename_coords(name: str):\n",
    "    m = re.search(r\"J(\\d{2})(\\d{2})([+-])(\\d{2})(\\d{2})\", name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse J‑name coordinates from '{name}'\")\n",
    "    ra_h, ra_m   = int(m.group(1)), int(m.group(2))\n",
    "    sign         = 1 if m.group(3) == \"+\" else -1\n",
    "    dec_d, dec_m = int(m.group(4)), int(m.group(5))\n",
    "    ra_deg  = (ra_h + ra_m/60) * 15.0\n",
    "    dec_deg = sign * (dec_d + dec_m/60)\n",
    "    return ra_deg, dec_deg\n",
    "\n",
    "\n",
    "# first cone-search on the Fan 2023 database to extract precise coordinates\n",
    "def find_closest_in_ods(ods_file, target_ra, target_dec):\n",
    "    df = pd.read_excel(ods_file, engine=\"odf\", header=[0, 1])\n",
    "    ra_col  = [c for c in df.columns if c[0].lower() == \"ra\"][0]\n",
    "    dec_col = [c for c in df.columns if c[0].lower() == \"dec\"][0]\n",
    "    z_col   = [c for c in df.columns if c[0].lower() == \"redshift\"]\n",
    "    z_col   = z_col[0] if z_col else None\n",
    "\n",
    "    df[ra_col]  = pd.to_numeric(df[ra_col],  errors=\"coerce\")\n",
    "    df[dec_col] = pd.to_numeric(df[dec_col], errors=\"coerce\")\n",
    "\n",
    "    target  = SkyCoord(target_ra*u.deg, target_dec*u.deg)\n",
    "    coords  = SkyCoord(df[ra_col].values*u.deg, df[dec_col].values*u.deg)\n",
    "    idx     = target.separation(coords).argmin()\n",
    "    row     = df.iloc[idx]\n",
    "    z_val   = row[z_col] if z_col else np.nan\n",
    "    return float(row[ra_col]), float(row[dec_col]), z_val\n",
    "\n",
    "\n",
    "# cone-search with precise ra/dec values from Fan 2023 database on the catalog entries\n",
    "# SET MAXIMUM SEPARATION AT SETTINGS ABOVE, max_sep here is only default value!!!\n",
    "def find_closest_in_catalog(cat_path, target_ra, target_dec, max_sep=2.0):\n",
    "    cat = Table.read(cat_path, format=\"ascii\")\n",
    "    if not {\"ALPHA_J2000\", \"DELTA_J2000\"}.issubset(cat.colnames):\n",
    "        raise ValueError(f\"{cat_path}: missing RA/Dec columns\")\n",
    "\n",
    "    target    = SkyCoord(target_ra*u.deg, target_dec*u.deg)\n",
    "    cat_coord = SkyCoord(cat[\"ALPHA_J2000\"], cat[\"DELTA_J2000\"], unit=\"deg\")\n",
    "    sep       = target.separation(cat_coord)\n",
    "    if sep.min() > max_sep*u.arcsec:\n",
    "        raise ValueError(f\"No match within {max_sep} arcsec (closest={sep.min().arcsec:.2f})\")\n",
    "    row = cat[sep.argmin()]\n",
    "    # return only numeric types or None (float(row[col]) if present else None)\n",
    "    def get(col):\n",
    "        return float(row[col]) if col in row.colnames and row[col] is not None else np.nan\n",
    "    return dict(\n",
    "        ALPHA_J2000 = get(\"ALPHA_J2000\"),\n",
    "        DELTA_J2000 = get(\"DELTA_J2000\"),\n",
    "        MAG_APER    = get(\"MAG_APER\"),\n",
    "        MAGERR_APER = get(\"MAGERR_APER\"),\n",
    "        FLUX_APER   = get(\"FLUX_APER\"),\n",
    "        FLUXERR_APER= get(\"FLUXERR_APER\"),\n",
    "        X_IMAGE     = get(\"X_IMAGE\"),\n",
    "        Y_IMAGE     = get(\"Y_IMAGE\"),\n",
    "    )\n",
    "\n",
    "\n",
    "# reverse engineered from bash-script output\n",
    "def extract_zpd_from_filename(fname):\n",
    "    z  = re.search(r\"_ZPD([0-9p\\-]+)\", fname)\n",
    "    ze = re.search(r\"_ERR([0-9p\\-]+)\", fname)\n",
    "    zpd     = float(z.group(1).replace('p','.'))  if z else np.nan\n",
    "    zpd_err = float(ze.group(1).replace('p','.')) if ze else np.nan\n",
    "    return zpd, zpd_err\n",
    "\n",
    "\n",
    "# poisson error (flux) to asymmetric magerr\n",
    "def flux_to_magerr_asymmetric(flux, flux_err):\n",
    "    if flux <= 0 or flux_err <= 0 or flux_err >= flux:\n",
    "        return np.nan, np.nan\n",
    "    mag     = -2.5 * np.log10(flux)\n",
    "    mag_plus  = -2.5 * np.log10(flux - flux_err)\n",
    "    mag_minus = -2.5 * np.log10(flux + flux_err)\n",
    "    err_plus  = mag_plus - mag\n",
    "    err_minus = mag - mag_minus\n",
    "    return err_plus, err_minus\n",
    "\n",
    "\n",
    "# asymmetric error calculation\n",
    "def background_flux_to_magerr_asymmetric(flux, bg_err):\n",
    "    if flux <= 0 or bg_err is None or bg_err <= 0 or bg_err >= flux:\n",
    "        return np.nan, np.nan\n",
    "    mag     = -2.5 * np.log10(flux)\n",
    "    mag_plus  = -2.5 * np.log10(flux - bg_err)\n",
    "    mag_minus = -2.5 * np.log10(flux + bg_err)\n",
    "    err_plus  = mag_plus - mag\n",
    "    err_minus = mag - mag_minus\n",
    "    return err_plus, err_minus\n",
    "\n",
    "# safe quadratic summation, where it prints nan for failed calculation instead of stopping (very neat)\n",
    "def safe_quad_sum(*errs):\n",
    "    errs_clean = [e for e in errs if np.isfinite(e)]\n",
    "    return np.sqrt(np.sum(np.square(errs_clean))) if errs_clean else np.nan\n",
    "\n",
    "\n",
    "# background error estimation by quadrature summing of background_rms map. SET ONLY DEFAULT METHOD HERE!!!\n",
    "def compute_background_error_photutils(rms_path, x, y, diameter, method=\"center\"):\n",
    "    try:\n",
    "        with fits.open(rms_path) as hdul:\n",
    "            data = hdul[0].data\n",
    "        r   = diameter/2.0\n",
    "        ap  = CircularAperture([(x, y)], r=r)\n",
    "        s2  = aperture_photometry(data**2, ap, method=method)['aperture_sum'][0]\n",
    "        return np.sqrt(s2)\n",
    "    except Exception as e:\n",
    "        print(f\"Background error failed ({os.path.basename(rms_path)}): {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2.  MAIN LOOP\n",
    "# ----------------------------------------------------------------------\n",
    "records = []\n",
    "\n",
    "for cat_file in sorted(os.listdir(catalog_folder)):\n",
    "    if not cat_file.endswith(\".cat\"):\n",
    "        continue\n",
    "\n",
    "    base_match = re.match(r\"(J\\d{4}[+-]\\d{4}(?:\\(dup\\))?)\", cat_file)\n",
    "    if not base_match:\n",
    "        print(f\"Skipping {cat_file}: cannot extract J‑name\")\n",
    "        continue\n",
    "    base = base_match.group(1)\n",
    "\n",
    "    try:\n",
    "        rough_ra, rough_dec = parse_filename_coords(base)\n",
    "        ra_prec, dec_prec, z = find_closest_in_ods(ods_file_path, rough_ra, rough_dec)\n",
    "\n",
    "        cat_path = os.path.join(catalog_folder, cat_file)\n",
    "        phot = find_closest_in_catalog(cat_path, ra_prec, dec_prec, max_sep=MAX_SEP_ARCSEC)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {cat_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # grab aperture diameter from filename\n",
    "    ap_match = re.search(r\"_ap([0-9p]+)\", cat_file)\n",
    "    aper_diam = float(ap_match.group(1).replace('p','.')) if ap_match else 1.0\n",
    "\n",
    "    zpd, zpd_err = extract_zpd_from_filename(cat_file)\n",
    "\n",
    "    # background RMS calculation (SET IN-USE method HERE, ABOVE IS DEFAULT METHOD!!!)\n",
    "    rms_file = f\"{base}_ap{ap_match.group(1)}_background_rms.fits\"\n",
    "    rms_path = os.path.join(background_rms_folder, rms_file)\n",
    "    bg_err   = compute_background_error_photutils(\n",
    "                    rms_path, phot[\"X_IMAGE\"], phot[\"Y_IMAGE\"], aper_diam, method=\"exact\") \n",
    "\n",
    "    # read and truncate DATEOBS1 to give exposure date\n",
    "    try:\n",
    "        with fits.open(rms_path) as hd:\n",
    "            dateobs1 = hd[0].header.get(\"DATEOBS1\", \"\")\n",
    "        obs_date = dateobs1.split('T')[0] if \"T\" in dateobs1 else dateobs1\n",
    "    except Exception:\n",
    "        obs_date = \"\"\n",
    "\n",
    "    # magnitude‑error budget\n",
    "    m_err_plus, m_err_minus = flux_to_magerr_asymmetric(\n",
    "                                phot[\"FLUX_APER\"], phot[\"FLUXERR_APER\"])\n",
    "    bg_err_plus, bg_err_minus = background_flux_to_magerr_asymmetric(\n",
    "                                phot[\"FLUX_APER\"], bg_err)\n",
    "\n",
    "    magerrtot_plus  = safe_quad_sum(zpd_err, bg_err_plus,  m_err_plus)\n",
    "    magerrtot_minus = safe_quad_sum(zpd_err, bg_err_minus, m_err_minus)\n",
    "\n",
    "    # Calculate SNR\n",
    "    snr = phot[\"FLUX_APER\"] / bg_err if bg_err > 0 else np.nan\n",
    "\n",
    "    # SkyCoord formatted clean strings\n",
    "    c_prec = SkyCoord(ra_prec*u.deg, dec_prec*u.deg)\n",
    "    ra_sex = c_prec.ra.to_string(unit=u.hourangle, sep=':', precision=2, pad=True)\n",
    "    dec_sex= c_prec.dec.to_string(unit=u.deg,       sep=':', precision=2, pad=True, alwayssign=True)\n",
    "\n",
    "    records.append(dict(\n",
    "        Filename          = cat_file,\n",
    "        PreciseRA         = ra_prec,\n",
    "        PreciseDEC        = dec_prec,\n",
    "        PreciseRA_sex     = ra_sex,\n",
    "        PreciseDEC_sex    = dec_sex,\n",
    "        Redshift          = z,\n",
    "        ALPHA_J2000       = phot[\"ALPHA_J2000\"],\n",
    "        DELTA_J2000       = phot[\"DELTA_J2000\"],\n",
    "        MAG_APER          = phot[\"MAG_APER\"],\n",
    "        MAGERR_APER       = phot[\"MAGERR_APER\"],\n",
    "        FLUX_APER         = phot[\"FLUX_APER\"],\n",
    "        FLUXERR_APER      = phot[\"FLUXERR_APER\"],\n",
    "        X_IMAGE           = phot[\"X_IMAGE\"],\n",
    "        Y_IMAGE           = phot[\"Y_IMAGE\"],\n",
    "        Aperture          = aper_diam,\n",
    "        ZPD               = zpd,\n",
    "        ZPD_ERR           = zpd_err,\n",
    "        Background_ERR    = bg_err,\n",
    "        MAGERR_FROMFLUXAPER_PLUS   = m_err_plus,\n",
    "        MAGERR_FROMFLUXAPER_MINUS  = m_err_minus,\n",
    "        Background_ERR_upper       = bg_err_plus,\n",
    "        Background_ERR_lower       = bg_err_minus,\n",
    "        MAGERRTOT_upper            = magerrtot_plus,\n",
    "        MAGERRTOT_lower            = magerrtot_minus,\n",
    "        ObservationDate            = obs_date,\n",
    "        SNR                       = snr \n",
    "    ))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3.  WRITE TSV\n",
    "# ----------------------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(\n",
    "    output_file, sep=\"\\t\", index=False,\n",
    "    columns=[\n",
    "        \"Filename\",\"PreciseRA\",\"PreciseDEC\",\"PreciseRA_sex\",\"PreciseDEC_sex\",\"Redshift\",\n",
    "        \"ALPHA_J2000\",\"DELTA_J2000\",\"MAG_APER\",\"MAGERR_APER\",\n",
    "        \"FLUX_APER\",\"FLUXERR_APER\",\"X_IMAGE\",\"Y_IMAGE\",\"Aperture\",\n",
    "        \"ZPD\",\"ZPD_ERR\",\"Background_ERR\",\n",
    "        \"MAGERR_FROMFLUXAPER_PLUS\",\"MAGERR_FROMFLUXAPER_MINUS\",\n",
    "        \"Background_ERR_upper\",\"Background_ERR_lower\",\n",
    "        \"MAGERRTOT_upper\",\"MAGERRTOT_lower\",\"ObservationDate\",\n",
    "        \"SNR\"               \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"✓ Finished – output saved to {output_file}\")\n",
    "print(f\"Total runtime: {time.time()-start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d0e12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping J0055+0146_ap5p0_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest=10.30)\n",
      "Skipping J0055+0146_ap7p0_ZPD24p4390_ERR0p0140.cat: No match within 2.0 arcsec (closest=10.30)\n",
      "Skipping J0909+0440_ap5p0_ZPD24p3890_ERR0p0210.cat: No match within 2.0 arcsec (closest=7.68)\n",
      "Skipping J0909+0440_ap7p0_ZPD24p3890_ERR0p0210.cat: No match within 2.0 arcsec (closest=7.68)\n",
      "Skipping J1350-0027_ap5p0_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest=9.55)\n",
      "Skipping J1350-0027_ap7p0_ZPD24p2930_ERR0p0240.cat: No match within 2.0 arcsec (closest=9.55)\n",
      "Skipping J1357-0843_ap5p0_ZPD24p4340_ERR0p0130.cat: No match within 2.0 arcsec (closest=3.83)\n",
      "Skipping J1357-0843_ap7p0_ZPD24p4340_ERR0p0130.cat: No match within 2.0 arcsec (closest=3.83)\n",
      "Skipping J2227-3323_ap5p0_ZPD23p9330_ERR0p0170.cat: No match within 2.0 arcsec (closest=7.29)\n",
      "Skipping J2227-3323_ap7p0_ZPD23p9330_ERR0p0170.cat: No match within 2.0 arcsec (closest=7.29)\n",
      "✓ Finished – output saved to /home/jk/Desktop/reduced1/onlyfits/photometry_matches.tsv\n",
      "Total runtime: 45.02 s\n"
     ]
    }
   ],
   "source": [
    "# crackcode, last minute\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os, re, time, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "from photutils.aperture import CircularAperture, aperture_photometry\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 0.  SETTINGS\n",
    "# ----------------------------------------------------------------------\n",
    "catalog_folder        = \"/home/jk/Desktop/reduced1/onlyfits/catalogs\"\n",
    "background_rms_folder = \"/home/jk/Desktop/reduced1/onlyfits/backgrounds_rms\"\n",
    "ods_file_path         = \"/home/jk/Desktop/aa61_fan_qso_database.ods\"\n",
    "output_file           = \"/home/jk/Desktop/reduced1/onlyfits/photometry_matches.tsv\"\n",
    "\n",
    "MAX_SEP_ARCSEC = 2.0          # match radius of precise RA/DEC from Fan23 with catalog detections\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1.  HELPER FUNCTIONS\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def parse_filename_coords(name: str):\n",
    "    \"\"\"Parse truncated J-name and return rough RA/Dec in degrees.\"\"\"\n",
    "    m = re.search(r\"J(\\d{2})(\\d{2})([+-])(\\d{2})(\\d{2})\", name)\n",
    "    if not m:\n",
    "        raise ValueError(f\"Cannot parse J-name coordinates from '{name}'\")\n",
    "    ra_h, ra_m   = int(m.group(1)), int(m.group(2))\n",
    "    sign         = 1 if m.group(3) == \"+\" else -1\n",
    "    dec_d, dec_m = int(m.group(4)), int(m.group(5))\n",
    "    ra_deg  = (ra_h + ra_m/60) * 15.0\n",
    "    dec_deg = sign * (dec_d + dec_m/60)\n",
    "    return ra_deg, dec_deg\n",
    "\n",
    "\n",
    "def find_closest_in_ods(ods_file, target_ra, target_dec):\n",
    "    \"\"\"\n",
    "    Cone-search the Fan+2023 ODS catalogue. \n",
    "    Returns precise RA, Dec, redshift, **and BH mass (10^8 M_sun)**.\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(ods_file, engine=\"odf\", header=[0, 1])\n",
    "\n",
    "    ra_col  = [c for c in df.columns if c[0].lower() == \"ra\"][0]\n",
    "    dec_col = [c for c in df.columns if c[0].lower() == \"dec\"][0]\n",
    "    z_col   = [c for c in df.columns if c[0].lower() == \"redshift\"]\n",
    "    z_col   = z_col[0] if z_col else None\n",
    "\n",
    "    # Debug BHmass lookup with safer match\n",
    "    bh_cols = [c for c in df.columns if c[0].strip().lower() == \"bhmass\"]\n",
    "    bh_col = bh_cols[0] if bh_cols else None\n",
    "\n",
    "\n",
    "    target  = SkyCoord(target_ra*u.deg, target_dec*u.deg)\n",
    "    coords  = SkyCoord(df[ra_col].values*u.deg, df[dec_col].values*u.deg)\n",
    "    idx     = target.separation(coords).argmin()\n",
    "    row     = df.iloc[idx]\n",
    "    z_val   = row[z_col] if z_col else np.nan\n",
    "    bh_mass = row[bh_col] if bh_col else np.nan\n",
    "\n",
    "    return float(row[ra_col]), float(row[dec_col]), z_val, bh_mass\n",
    "\n",
    "\n",
    "def find_closest_in_catalog(cat_path, target_ra, target_dec, max_sep=2.0):\n",
    "    \"\"\"Cone-search inside one SExtractor catalogue.\"\"\"\n",
    "    cat = Table.read(cat_path, format=\"ascii\")\n",
    "    if not {\"ALPHA_J2000\", \"DELTA_J2000\"}.issubset(cat.colnames):\n",
    "        raise ValueError(f\"{cat_path}: missing RA/Dec columns\")\n",
    "\n",
    "    target    = SkyCoord(target_ra*u.deg, target_dec*u.deg)\n",
    "    cat_coord = SkyCoord(cat[\"ALPHA_J2000\"], cat[\"DELTA_J2000\"], unit=\"deg\")\n",
    "    sep       = target.separation(cat_coord)\n",
    "    if sep.min() > max_sep*u.arcsec:\n",
    "        raise ValueError(f\"No match within {max_sep} arcsec (closest={sep.min().arcsec:.2f})\")\n",
    "    row = cat[sep.argmin()]\n",
    "    def get(col):\n",
    "        return float(row[col]) if col in row.colnames and row[col] is not None else np.nan\n",
    "    return dict(\n",
    "        ALPHA_J2000 = get(\"ALPHA_J2000\"),\n",
    "        DELTA_J2000 = get(\"DELTA_J2000\"),\n",
    "        MAG_APER    = get(\"MAG_APER\"),\n",
    "        MAGERR_APER = get(\"MAGERR_APER\"),\n",
    "        FLUX_APER   = get(\"FLUX_APER\"),\n",
    "        FLUXERR_APER= get(\"FLUXERR_APER\"),\n",
    "        X_IMAGE     = get(\"X_IMAGE\"),\n",
    "        Y_IMAGE     = get(\"Y_IMAGE\"),\n",
    "    )\n",
    "\n",
    "def extract_zpd_from_filename(fname):\n",
    "    z  = re.search(r\"_ZPD([0-9p\\-]+)\", fname)\n",
    "    ze = re.search(r\"_ERR([0-9p\\-]+)\", fname)\n",
    "    zpd     = float(z.group(1).replace('p','.'))  if z else np.nan\n",
    "    zpd_err = float(ze.group(1).replace('p','.')) if ze else np.nan\n",
    "    return zpd, zpd_err\n",
    "\n",
    "# --- (the rest of helper functions unchanged) ---\n",
    "def flux_to_magerr_asymmetric(flux, flux_err):\n",
    "    if flux <= 0 or flux_err <= 0 or flux_err >= flux:\n",
    "        return np.nan, np.nan\n",
    "    mag     = -2.5 * np.log10(flux)\n",
    "    mag_plus  = -2.5 * np.log10(flux - flux_err)\n",
    "    mag_minus = -2.5 * np.log10(flux + flux_err)\n",
    "    err_plus  = mag_plus - mag\n",
    "    err_minus = mag - mag_minus\n",
    "    return err_plus, err_minus\n",
    "\n",
    "def background_flux_to_magerr_asymmetric(flux, bg_err):\n",
    "    if flux <= 0 or bg_err is None or bg_err <= 0 or bg_err >= flux:\n",
    "        return np.nan, np.nan\n",
    "    mag     = -2.5 * np.log10(flux)\n",
    "    mag_plus  = -2.5 * np.log10(flux - bg_err)\n",
    "    mag_minus = -2.5 * np.log10(flux + bg_err)\n",
    "    err_plus  = mag_plus - mag\n",
    "    err_minus = mag - mag_minus\n",
    "    return err_plus, err_minus\n",
    "\n",
    "def safe_quad_sum(*errs):\n",
    "    errs_clean = [e for e in errs if np.isfinite(e)]\n",
    "    return np.sqrt(np.sum(np.square(errs_clean))) if errs_clean else np.nan\n",
    "\n",
    "def compute_background_error_photutils(rms_path, x, y, diameter, method=\"center\"):\n",
    "    try:\n",
    "        with fits.open(rms_path) as hdul:\n",
    "            data = hdul[0].data\n",
    "        r   = diameter/2.0\n",
    "        ap  = CircularAperture([(x, y)], r=r)\n",
    "        s2  = aperture_photometry(data**2, ap, method=method)['aperture_sum'][0]\n",
    "        return np.sqrt(s2)\n",
    "    except Exception as e:\n",
    "        print(f\"Background error failed ({os.path.basename(rms_path)}): {e}\")\n",
    "        return np.nan\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2.  MAIN LOOP\n",
    "# ----------------------------------------------------------------------\n",
    "records = []\n",
    "\n",
    "for cat_file in sorted(os.listdir(catalog_folder)):\n",
    "    if not cat_file.endswith(\".cat\"):\n",
    "        continue\n",
    "\n",
    "    base_match = re.match(r\"(J\\d{4}[+-]\\d{4}(?:\\(dup\\))?)\", cat_file)\n",
    "    if not base_match:\n",
    "        print(f\"Skipping {cat_file}: cannot extract J-name\")\n",
    "        continue\n",
    "    base = base_match.group(1)\n",
    "\n",
    "    try:\n",
    "        rough_ra, rough_dec = parse_filename_coords(base)\n",
    "        ra_prec, dec_prec, z, bh_mass = find_closest_in_ods(\n",
    "            ods_file_path, rough_ra, rough_dec)\n",
    "\n",
    "        cat_path = os.path.join(catalog_folder, cat_file)\n",
    "        phot = find_closest_in_catalog(cat_path, ra_prec, dec_prec,\n",
    "                                       max_sep=MAX_SEP_ARCSEC)\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {cat_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # grab aperture diameter from filename\n",
    "    ap_match = re.search(r\"_ap([0-9p]+)\", cat_file)\n",
    "    aper_diam = float(ap_match.group(1).replace('p','.')) if ap_match else 1.0\n",
    "\n",
    "    zpd, zpd_err = extract_zpd_from_filename(cat_file)\n",
    "\n",
    "    # background RMS calculation\n",
    "    rms_file = f\"{base}_ap{ap_match.group(1)}_background_rms.fits\"\n",
    "    rms_path = os.path.join(background_rms_folder, rms_file)\n",
    "    bg_err   = compute_background_error_photutils(\n",
    "                    rms_path, phot[\"X_IMAGE\"], phot[\"Y_IMAGE\"],\n",
    "                    aper_diam, method=\"exact\") \n",
    "\n",
    "    # read and truncate DATEOBS1 to give exposure date\n",
    "    try:\n",
    "        with fits.open(rms_path) as hd:\n",
    "            dateobs1 = hd[0].header.get(\"DATEOBS1\", \"\")\n",
    "        obs_date = dateobs1.split('T')[0] if \"T\" in dateobs1 else dateobs1\n",
    "    except Exception:\n",
    "        obs_date = \"\"\n",
    "\n",
    "    # magnitude-error budget\n",
    "    m_err_plus, m_err_minus = flux_to_magerr_asymmetric(\n",
    "                                phot[\"FLUX_APER\"], phot[\"FLUXERR_APER\"])\n",
    "    bg_err_plus, bg_err_minus = background_flux_to_magerr_asymmetric(\n",
    "                                phot[\"FLUX_APER\"], bg_err)\n",
    "\n",
    "    magerrtot_plus  = safe_quad_sum(zpd_err, bg_err_plus,  m_err_plus)\n",
    "    magerrtot_minus = safe_quad_sum(zpd_err, bg_err_minus, m_err_minus)\n",
    "\n",
    "    # Calculate SNR\n",
    "    snr = phot[\"FLUX_APER\"] / bg_err if bg_err > 0 else np.nan\n",
    "\n",
    "    # SkyCoord formatted clean strings\n",
    "    c_prec = SkyCoord(ra_prec*u.deg, dec_prec*u.deg)\n",
    "    ra_sex = c_prec.ra.to_string(unit=u.hourangle, sep=':', precision=2, pad=True)\n",
    "    dec_sex= c_prec.dec.to_string(unit=u.deg,       sep=':', precision=2, pad=True,\n",
    "                                  alwayssign=True)\n",
    "\n",
    "    records.append(dict(\n",
    "        Filename          = cat_file,\n",
    "        PreciseRA         = ra_prec,\n",
    "        PreciseDEC        = dec_prec,\n",
    "        PreciseRA_sex     = ra_sex,\n",
    "        PreciseDEC_sex    = dec_sex,\n",
    "        Redshift          = z,\n",
    "        BHmass_1e8Msun    = bh_mass,             \n",
    "        ALPHA_J2000       = phot[\"ALPHA_J2000\"],\n",
    "        DELTA_J2000       = phot[\"DELTA_J2000\"],\n",
    "        MAG_APER          = phot[\"MAG_APER\"],\n",
    "        MAGERR_APER       = phot[\"MAGERR_APER\"],\n",
    "        FLUX_APER         = phot[\"FLUX_APER\"],\n",
    "        FLUXERR_APER      = phot[\"FLUXERR_APER\"],\n",
    "        X_IMAGE           = phot[\"X_IMAGE\"],\n",
    "        Y_IMAGE           = phot[\"Y_IMAGE\"],\n",
    "        Aperture          = aper_diam,\n",
    "        ZPD               = zpd,\n",
    "        ZPD_ERR           = zpd_err,\n",
    "        Background_ERR    = bg_err,\n",
    "        MAGERR_FROMFLUXAPER_PLUS   = m_err_plus,\n",
    "        MAGERR_FROMFLUXAPER_MINUS  = m_err_minus,\n",
    "        Background_ERR_upper       = bg_err_plus,\n",
    "        Background_ERR_lower       = bg_err_minus,\n",
    "        MAGERRTOT_upper            = magerrtot_plus,\n",
    "        MAGERRTOT_lower            = magerrtot_minus,\n",
    "        ObservationDate            = obs_date,\n",
    "        SNR                        = snr \n",
    "    ))\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 3.  WRITE TSV\n",
    "# ----------------------------------------------------------------------\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv(\n",
    "    output_file, sep=\"\\t\", index=False,\n",
    "    columns=[\n",
    "        \"Filename\",\"PreciseRA\",\"PreciseDEC\",\"PreciseRA_sex\",\"PreciseDEC_sex\",\"Redshift\",\n",
    "        \"BHmass_1e8Msun\",                     \n",
    "        \"ALPHA_J2000\",\"DELTA_J2000\",\"MAG_APER\",\"MAGERR_APER\",\n",
    "        \"FLUX_APER\",\"FLUXERR_APER\",\"X_IMAGE\",\"Y_IMAGE\",\"Aperture\",\n",
    "        \"ZPD\",\"ZPD_ERR\",\"Background_ERR\",\n",
    "        \"MAGERR_FROMFLUXAPER_PLUS\",\"MAGERR_FROMFLUXAPER_MINUS\",\n",
    "        \"Background_ERR_upper\",\"Background_ERR_lower\",\n",
    "        \"MAGERRTOT_upper\",\"MAGERRTOT_lower\",\"ObservationDate\",\n",
    "        \"SNR\"               \n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"✓ Finished – output saved to {output_file}\")\n",
    "print(f\"Total runtime: {time.time() - start:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db261dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c433c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
